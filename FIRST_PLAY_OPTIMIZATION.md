# Optimisation de la Premi√®re Lecture Audio - Analyse Technique

**Date:** 2025-01-XX  
**Version:** v0.4.1  
**Focus:** R√©duction du temps de g√©n√©ration audio lors de la premi√®re lecture d'une r√©plique

---

## üìä √âtat Actuel du Pipeline TTS

### Flow de G√©n√©ration (Premi√®re Lecture)

```
User Click sur R√©plique
    ‚Üì
1. V√©rification Cache AudioCacheService
   ‚îú‚îÄ ‚úÖ Trouv√© ‚Üí Lecture imm√©diate (~50-100ms)
   ‚îî‚îÄ ‚ùå Pas trouv√© ‚Üí G√©n√©ration n√©cessaire
    ‚Üì
2. Chargement Session TTS (si pas en cache)
   ‚îú‚îÄ T√©l√©chargement mod√®le ONNX (~60-76 MB)
   ‚îú‚îÄ Chargement en m√©moire
   ‚îú‚îÄ Initialisation ONNX Runtime
   ‚îî‚îÄ Temps: 2000-5000ms (premi√®re fois)
    ‚Üì
3. Phon√©misation du Texte
   ‚îú‚îÄ Conversion texte ‚Üí phon√®mes (espeak-ng)
   ‚îú‚îÄ G√©r√©e en interne par piper-tts-web
   ‚îî‚îÄ Temps: 50-200ms
    ‚Üì
4. Inf√©rence ONNX
   ‚îú‚îÄ G√©n√©ration audio via mod√®le neuronal
   ‚îú‚îÄ CPU/WASM single-threaded
   ‚îî‚îÄ Temps: 500-2000ms (selon longueur texte)
    ‚Üì
5. Post-traitement
   ‚îú‚îÄ Cr√©ation Blob audio
   ‚îú‚îÄ Mise en cache IndexedDB
   ‚îú‚îÄ Application modifiers (rate, pitch, volume)
   ‚îî‚îÄ Temps: 50-100ms
    ‚Üì
6. Lecture Audio
   ‚îî‚îÄ Temps: Dur√©e de l'audio
```

**Temps Total (Premi√®re Lecture):**
- R√©plique courte (10-20 mots): **3-6 secondes**
- R√©plique moyenne (30-50 mots): **4-8 secondes**
- R√©plique longue (100+ mots): **6-12 secondes**

---

## üéØ Opportunit√©s d'Optimisation

### 1. Preloading Pr√©dictif des Sessions ‚≠ê‚≠ê‚≠ê

#### Probl√®me Actuel
La session TTS (mod√®le ONNX) n'est charg√©e qu'au moment du premier clic. Cela ajoute **2-5 secondes** de latence.

#### Solution: Preload Intelligent

**A. Preload au Chargement de la Pi√®ce**

```typescript
// src/screens/PlayScreen.tsx
useEffect(() => {
  if (currentPlay && playSettings) {
    // Identifier les voix utilis√©es dans la sc√®ne courante
    const voicesInScene = getVoicesForCurrentScene(
      currentPlay,
      playSettings,
      currentActIndex,
      currentSceneIndex
    )
    
    // Preloader les 2-3 premi√®res voix (prioriser par usage)
    const priorityVoices = voicesInScene.slice(0, 3)
    
    Promise.all(
      priorityVoices.map(voiceId => 
        ttsProviderManager.getActiveProvider().preloadModel(voiceId)
      )
    ).then(() => {
      console.log('‚úÖ Voix principales pr√©charg√©es')
    })
  }
}, [currentPlay, currentActIndex, currentSceneIndex])
```

**Impact:**
- ‚úÖ Premi√®re lecture: **3-6s ‚Üí 1-2s** (-60-70%)
- ‚úÖ Sessions en cache pour toute la sc√®ne
- ‚ö†Ô∏è Augmentation m√©moire: +150-200 MB (2-3 mod√®les)

**B. Preload Progressif en Arri√®re-Plan**

```typescript
// Preload pendant la lecture
async function preloadNextVoices(currentLineIndex: number) {
  const nextLines = getNextLines(currentLineIndex, 5) // 5 prochaines r√©pliques
  const nextVoices = new Set(nextLines.map(line => getVoiceForLine(line)))
  
  for (const voiceId of nextVoices) {
    if (!sessionCache.has(voiceId)) {
      await ttsProviderManager.getActiveProvider().preloadModel(voiceId)
    }
  }
}
```

**Impact:**
- ‚úÖ Preload invisible pour l'utilisateur
- ‚úÖ Sessions pr√™tes avant que l'utilisateur arrive
- ‚ö†Ô∏è Bande passante utilis√©e en arri√®re-plan

---

### 2. Prefetching Audio des Prochaines R√©pliques ‚≠ê‚≠ê‚≠ê

#### Probl√®me Actuel
Chaque r√©plique est g√©n√©r√©e au moment du clic. Aucune anticipation.

#### Solution: G√©n√©ration Anticip√©e

**A. Prefetch des N Prochaines R√©pliques**

```typescript
// src/utils/audioPrefetcher.ts
class AudioPrefetcher {
  private prefetchQueue: Set<number> = new Set()
  private isProcessing = false
  
  async prefetchNextLines(currentLineIndex: number, count: number = 3) {
    const nextLines = getNextLines(currentLineIndex, count)
    
    for (const line of nextLines) {
      // V√©rifier si d√©j√† en cache
      const cached = await audioCacheService.getAudio(
        line.text,
        getVoiceForLine(line)
      )
      
      if (!cached && !this.prefetchQueue.has(line.index)) {
        this.prefetchQueue.add(line.index)
        this.processPrefetchQueue()
      }
    }
  }
  
  private async processPrefetchQueue() {
    if (this.isProcessing) return
    this.isProcessing = true
    
    while (this.prefetchQueue.size > 0) {
      const lineIndex = this.prefetchQueue.values().next().value
      this.prefetchQueue.delete(lineIndex)
      
      try {
        // G√©n√©rer en arri√®re-plan (pas de lecture)
        await generateAudioSilently(lineIndex)
      } catch (error) {
        console.warn('Prefetch failed:', error)
      }
    }
    
    this.isProcessing = false
  }
}
```

**Usage:**

```typescript
// Apr√®s chaque lecture
onAudioEnd(() => {
  audioPrefetcher.prefetchNextLines(currentLineIndex, 3)
})
```

**Impact:**
- ‚úÖ R√©pliques suivantes d√©j√† g√©n√©r√©es
- ‚úÖ Lecture imm√©diate au clic (~50-100ms)
- ‚úÖ Exp√©rience fluide
- ‚ö†Ô∏è CPU utilis√© en arri√®re-plan
- ‚ö†Ô∏è Stockage IndexedDB augment√©

---

### 3. Optimisation de la Segmentation Texte ‚≠ê‚≠ê

#### Probl√®me Actuel
Les r√©pliques longues sont trait√©es en un seul bloc, augmentant le temps de g√©n√©ration.

#### Solution: Streaming Audio Progressif

**A. D√©composition Intelligente**

```typescript
// src/utils/textSegmentation.ts
function segmentTextForStreaming(text: string): string[] {
  const segments: string[] = []
  
  // S√©parer par phrases (. ! ?)
  const sentences = text.match(/[^.!?]+[.!?]+/g) || [text]
  
  let currentSegment = ''
  const MAX_WORDS_PER_SEGMENT = 20
  
  for (const sentence of sentences) {
    const words = sentence.split(' ')
    
    if (currentSegment.split(' ').length + words.length > MAX_WORDS_PER_SEGMENT) {
      if (currentSegment) segments.push(currentSegment.trim())
      currentSegment = sentence
    } else {
      currentSegment += ' ' + sentence
    }
  }
  
  if (currentSegment) segments.push(currentSegment.trim())
  
  return segments
}
```

**B. G√©n√©ration et Lecture en Streaming**

```typescript
async function playTextWithStreaming(text: string, voiceId: string) {
  const segments = segmentTextForStreaming(text)
  
  for (let i = 0; i < segments.length; i++) {
    const segment = segments[i]
    
    // G√©n√©rer segment actuel
    const audioPromise = ttsProviderManager.speak(segment, { voiceId })
    
    // Pr√©charger segment suivant en parall√®le
    if (i + 1 < segments.length) {
      generateAudioSilently(segments[i + 1], voiceId)
    }
    
    // Attendre et jouer segment actuel
    const { audio } = await audioPromise
    await playAudio(audio)
  }
}
```

**Impact:**
- ‚úÖ D√©but de lecture plus rapide (premier segment)
- ‚úÖ Perception de rapidit√© am√©lior√©e
- ‚úÖ Parall√©lisation g√©n√©ration + lecture
- ‚ö†Ô∏è Complexit√© accrue
- ‚ö†Ô∏è Gestion des pauses entre segments

---

### 4. Optimisation ONNX Runtime ‚≠ê‚≠ê

#### Probl√®me Actuel
ONNX Runtime utilise WASM single-threaded par d√©faut.

#### Solution: WebAssembly SIMD + Threads

**A. V√©rifier Configuration Actuelle**

```typescript
// src/core/tts/providers/PiperWASMProvider.ts
async initialize() {
  const ort = await import('onnxruntime-web')
  
  // V√©rifier support SIMD
  if (ort.env.wasm.simd) {
    console.log('‚úÖ SIMD activ√©')
  }
  
  // Activer threads si disponible
  ort.env.wasm.numThreads = navigator.hardwareConcurrency || 4
  ort.env.wasm.proxy = true // Web Worker
  
  console.log(`‚ö° ONNX Threads: ${ort.env.wasm.numThreads}`)
}
```

**B. Configuration Vite pour SharedArrayBuffer**

D√©j√† en place dans `vite.config.ts`:
```typescript
server: {
  headers: {
    'Cross-Origin-Embedder-Policy': 'credentialless',
    'Cross-Origin-Opener-Policy': 'same-origin',
  },
}
```

**Impact:**
- ‚úÖ Inf√©rence 2-4x plus rapide (multi-core)
- ‚úÖ Gain: 500-2000ms ‚Üí 200-800ms
- ‚ö†Ô∏è N√©cessite HTTPS + headers COOP/COEP

---

### 5. Cache Warmup au D√©marrage de l'App ‚≠ê

#### Probl√®me Actuel
Premi√®re visite = tout doit √™tre t√©l√©charg√© et g√©n√©r√©.

#### Solution: Warm Cache avec R√©pliques Communes

**A. G√©n√©rer Cache Initial**

```typescript
// src/core/tts/warmCache.ts
const COMMON_PHRASES = [
  'Bonjour',
  'Comment allez-vous ?',
  'Merci beaucoup',
  'Au revoir',
  // 20-30 phrases courantes du th√©√¢tre fran√ßais
]

async function warmAudioCache() {
  const voices = ['fr_FR-siwis-medium', 'fr_FR-tom-medium']
  
  for (const voiceId of voices) {
    // Preload mod√®le
    await ttsProviderManager.getActiveProvider().preloadModel(voiceId)
    
    // G√©n√©rer phrases communes
    for (const phrase of COMMON_PHRASES) {
      try {
        await ttsProviderManager.speak(phrase, { voiceId })
      } catch (error) {
        console.warn('Warm cache failed:', phrase, error)
      }
    }
  }
}

// Appeler au chargement de l'app (apr√®s un d√©lai)
setTimeout(() => warmAudioCache(), 5000)
```

**Impact:**
- ‚úÖ Sessions d√©j√† charg√©es
- ‚úÖ Cache IndexedDB pr√©-rempli
- ‚úÖ Phrases courantes instantan√©es
- ‚ö†Ô∏è Bande passante initiale importante
- ‚ö†Ô∏è D√©lai d'initialisation

---

### 6. Compression Audio et Format Optimis√© ‚≠ê

#### Probl√®me Actuel
Audio g√©n√©r√© en WAV non compress√© (volumineux).

#### Solution: Conversion Opus/MP3

**A. Compression Post-G√©n√©ration**

```typescript
async function compressAudio(audioBlob: Blob): Promise<Blob> {
  // Utiliser Web Audio API pour encoder en Opus
  const audioContext = new AudioContext()
  const arrayBuffer = await audioBlob.arrayBuffer()
  const audioBuffer = await audioContext.decodeAudioData(arrayBuffer)
  
  // Encoder en format compress√© (Opus ou MP3)
  const mediaRecorder = new MediaRecorder(
    audioContext.createMediaStreamSource(audioBuffer),
    { mimeType: 'audio/webm;codecs=opus' }
  )
  
  // ... recorder logic
  
  return compressedBlob
}
```

**Impact:**
- ‚úÖ Taille cache r√©duite de 70-80%
- ‚úÖ Plus d'audios en cache (quota)
- ‚ö†Ô∏è Temps de compression additionnel (+100-200ms)
- ‚ö†Ô∏è Perte qualit√© minime

---

### 7. Parall√©lisation Session + G√©n√©ration ‚≠ê‚≠ê

#### Probl√®me Actuel
Chargement session ‚Üí Puis g√©n√©ration (s√©quentiel).

#### Solution: Pipeline Parall√®le

**A. G√©n√©rer Pendant le Chargement**

```typescript
async function synthesizeWithParallelLoading(
  text: string,
  voiceId: string
): Promise<SynthesisResult> {
  // D√©marrer chargement session
  const sessionPromise = loadOrCreateSession(voiceId)
  
  // En parall√®le, pr√©parer le texte
  const textPreprocessingPromise = preprocessText(text)
  
  // Attendre les deux
  const [session, preprocessedText] = await Promise.all([
    sessionPromise,
    textPreprocessingPromise
  ])
  
  // Synth√©tiser
  return session.predict(preprocessedText)
}
```

**Impact:**
- ‚úÖ Gain: 50-100ms sur temps total
- ‚úÖ Optimisation CPU
- ‚ö†Ô∏è Gain marginal si preprocessing l√©ger

---

### 8. Didascalies: Voix D√©di√©e L√©g√®re ‚≠ê‚≠ê

#### Probl√®me Actuel
Didascalies utilisent le m√™me mod√®le que les r√©pliques.

#### Solution: Mod√®le L√©ger pour Didascalies

**A. Ajouter Voix Didascalie**

```typescript
// Utiliser un mod√®le plus petit et plus rapide pour les didascalies
const STAGE_DIRECTION_VOICE = {
  id: 'fr_FR-siwis-low',  // Mod√®le qualit√© "low" (~20 MB vs 60 MB)
  name: 'Didascalies (Rapide)',
  speakerId: 0,
}
```

**B. D√©tection Automatique**

```typescript
function getVoiceForSegment(segment: TextSegment, characterVoiceId: string) {
  if (segment.type === 'stage-direction') {
    return STAGE_DIRECTION_VOICE.id
  }
  return characterVoiceId
}
```

**Impact:**
- ‚úÖ G√©n√©ration didascalies 2-3x plus rapide
- ‚úÖ Moins de m√©moire utilis√©e
- ‚úÖ Qualit√© suffisante pour contexte
- ‚ö†Ô∏è Voix diff√©rente (peut √™tre voulu)

---

## üìä Plan d'Impl√©mentation Prioris√©

### Phase 1: Quick Wins (2-3h) ‚≠ê‚≠ê‚≠ê

**Impl√©mentations:**
1. ‚úÖ Preload sessions au chargement de sc√®ne
2. ‚úÖ Prefetch 2-3 prochaines r√©pliques
3. ‚úÖ V√©rifier config ONNX threads

**Gains estim√©s:**
- Premi√®re lecture: **3-6s ‚Üí 1-2s** (-60-70%)
- Lectures suivantes: **Quasi instantan√©es**

**Effort:** Faible - Modifications existantes

---

### Phase 2: Optimisations Avanc√©es (4-6h) ‚≠ê‚≠ê

**Impl√©mentations:**
1. ‚úÖ Streaming audio progressif
2. ‚úÖ Compression audio Opus
3. ‚úÖ Voix l√©g√®re pour didascalies

**Gains estim√©s:**
- Perception rapidit√©: **+50%**
- Stockage cache: **-70%**
- G√©n√©ration didascalies: **-50%**

**Effort:** Moyen - Nouveaux syst√®mes

---

### Phase 3: Optimisations Exp√©rimentales (6-8h) ‚≠ê

**Impl√©mentations:**
1. ‚ö° Cache warmup intelligent
2. ‚ö° Pipeline parall√®le avanc√©
3. ‚ö° Web Worker pour g√©n√©ration

**Gains estim√©s:**
- Premi√®re visite: **+30%**
- CPU utilisation: **Meilleure**

**Effort:** √âlev√© - Refactoring significatif

---

## üî¨ M√©triques √† Suivre

### KPIs Performance

```typescript
interface AudioGenerationMetrics {
  // Temps
  sessionLoadTime: number        // Chargement mod√®le ONNX
  phonemizationTime: number      // Conversion texte ‚Üí phon√®mes
  inferenceTime: number          // G√©n√©ration audio ONNX
  postProcessingTime: number     // Blob + cache + modifiers
  totalTime: number              // Temps total per√ßu
  
  // Cache
  cacheHitRate: number           // % hits vs miss
  cacheSizeMB: number            // Taille totale IndexedDB
  
  // Qualit√©
  userWaitTime: number           // Temps avant d√©but lecture
  prefetchSuccessRate: number    // % prefetch r√©ussis
}
```

### Outils de Mesure

```typescript
// src/utils/performanceMonitor.ts
class AudioPerformanceMonitor {
  startMeasure(lineIndex: number) {
    performance.mark(`audio-gen-start-${lineIndex}`)
  }
  
  endMeasure(lineIndex: number) {
    performance.mark(`audio-gen-end-${lineIndex}`)
    performance.measure(
      `audio-generation-${lineIndex}`,
      `audio-gen-start-${lineIndex}`,
      `audio-gen-end-${lineIndex}`
    )
    
    const measure = performance.getEntriesByName(
      `audio-generation-${lineIndex}`
    )[0]
    
    console.log(`‚è±Ô∏è Audio gen time: ${measure.duration.toFixed(0)}ms`)
  }
}
```

---

## üí° Recommandations Finales

### Court Terme (D√©ployer v0.4.2)

**Impl√©menter:**
1. ‚úÖ Preload sessions (Phase 1.1)
2. ‚úÖ Prefetch 2 prochaines r√©pliques (Phase 1.2)
3. ‚úÖ Monitoring performance

**Impact:**
- Gain imm√©diat: **60-70%** sur premi√®re lecture
- Effort: 2-3 heures
- Risque: Faible

### Moyen Terme (v0.5.0)

**Impl√©menter:**
1. ‚úÖ Streaming progressif
2. ‚úÖ Compression audio
3. ‚úÖ Tests utilisateurs

**Impact:**
- Exp√©rience per√ßue: **Tr√®s am√©lior√©e**
- Effort: 4-6 heures
- Risque: Moyen (tests requis)

### Long Terme (v0.6.0+)

**Explorer:**
1. üî¨ Web Worker pour g√©n√©ration
2. üî¨ Cache warmup pr√©dictif
3. üî¨ Mod√®les TTS plus l√©gers

**Impact:**
- Innovation continue
- Effort: Variable
- Risque: Exp√©rimental

---

## üéØ Objectifs de Performance

### Cibles v0.4.2 (Phase 1)

| M√©trique | Actuel | Cible | Am√©lioration |
|----------|--------|-------|--------------|
| Premi√®re lecture (courte) | 3-6s | 1-2s | **-60-70%** |
| Premi√®re lecture (moyenne) | 4-8s | 2-3s | **-60%** |
| Lectures suivantes | 50-100ms | 50-100ms | = (d√©j√† optimal) |
| Sessions pr√©charg√©es | 0 | 2-3 | ‚úÖ |
| R√©pliques prefetch | 0 | 2-3 | ‚úÖ |

### Cibles v0.5.0 (Phase 2)

| M√©trique | v0.4.2 | Cible | Am√©lioration |
|----------|--------|-------|--------------|
| Perception rapidit√© | Bon | Excellent | **+50%** |
| Cache utilis√© | 100% | 30% | **-70%** |
| Didascalies | 1-2s | 0.5-1s | **-50%** |

---

**Cr√©√© par:** AI Assistant  
**Derni√®re mise √† jour:** 2025-01-XX  
**Status:** üìã Plan d'action pr√™t pour impl√©mentation